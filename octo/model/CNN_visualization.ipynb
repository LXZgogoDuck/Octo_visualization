{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2025-02-25T05:08:20.550927Z",
     "end_time": "2025-02-25T05:09:00.327299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "beac18419be34c13ac97b5b912c61b15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BRIDGE dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 05:08:26.099086: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Place the can to the left of the pot.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 05:08:30.654 python[3727:70242] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-02-25 05:08:30.654 python[3727:70242] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Octo model checkpoint...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a3974e1b4be485c996e15698cb9189e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'tasks' is missing items compared to example_batch: {'pad_mask_dict/timestep', 'timestep', 'image_wrist', 'pad_mask_dict/image_wrist'}\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]WARNING:root:'observations' is missing items compared to example_batch: {'image_wrist', 'pad_mask_dict/timestep', 'task_completed', 'pad_mask_dict/image_wrist', 'timestep', 'pad_mask_dict/image_primary'}\n",
      "WARNING:root:No pad_mask_dict found. Nothing will be masked.\n",
      "WARNING:root:Skipping observation tokenizer: obs_wrist\n",
      "100%|██████████| 37/37 [00:20<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "from octo.model.octo_model import OctoModel\n",
    "model = OctoModel.load_pretrained(\"hf://rail-berkeley/octo-small-1.5\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2\n",
    "import jax\n",
    "from PIL import Image\n",
    "import mediapy as mp\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "### Load the BRIDGE Dataset\n",
    "print(\"Loading BRIDGE dataset...\")\n",
    "builder = tfds.builder_from_directory(builder_dir=\"gs://gresearch/robotics/bridge/0.1.0/\")\n",
    "ds = builder.as_dataset(split=\"train[:1]\")  # Load first episode\n",
    "\n",
    "# Extract a single episode\n",
    "episode = next(iter(ds))\n",
    "steps = list(episode[\"steps\"])\n",
    "\n",
    "# Resize images to 256x256 (default for Octo model)\n",
    "images = [cv2.resize(np.array(step[\"observation\"][\"image\"]), (256, 256)) for step in steps]\n",
    "\n",
    "# Extract goal image (last frame) & language instruction\n",
    "goal_image = images[-1]\n",
    "language_instruction = steps[0][\"observation\"][\"natural_language_instruction\"].numpy().decode()\n",
    "\n",
    "print(f\"Instruction: {language_instruction}\")\n",
    "for img in images:\n",
    "    cv2.imshow(\"Episode Frame\", img)\n",
    "    cv2.waitKey(100)  # Wait 100ms per frame\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "### Load the Pretrained Octo Model\n",
    "print(\"Loading Octo model checkpoint...\")\n",
    "model = OctoModel.load_pretrained(\"hf://rail-berkeley/octo-base-1.5\")\n",
    "\n",
    "WINDOW_SIZE = 2\n",
    "task = model.create_tasks(goals={\"image_primary\": goal_image[None]})   # for goal-conditioned\n",
    "task = model.create_tasks(texts=[language_instruction])                # for language conditioned\n",
    "\n",
    "pred_actions, true_actions, attention_maps_per_step = [], [], []\n",
    "for step in tqdm.trange(len(images) - (WINDOW_SIZE - 1)):\n",
    "    input_images = np.stack(images[step:step+WINDOW_SIZE])[None]\n",
    "    observation = {\n",
    "        'image_primary': input_images,\n",
    "        'timestep_pad_mask': np.full((1, input_images.shape[1]), True, dtype=bool)\n",
    "    }\n",
    "\n",
    "    # Get both predicted actions and attention maps\n",
    "    actions, attention_maps = model.sample_actions(\n",
    "        observation,\n",
    "        task,\n",
    "        unnormalization_statistics=model.dataset_statistics[\"bridge_dataset\"][\"action\"],\n",
    "        rng=jax.random.PRNGKey(0)\n",
    "    )\n",
    "\n",
    "    # Store predicted actions\n",
    "    pred_actions.append(actions[0])\n",
    "\n",
    "    # Store attention maps (for all layers & heads at this step)\n",
    "    attention_maps_per_step.append(attention_maps)\n",
    "\n",
    "    # Store true actions\n",
    "    final_window_step = step + WINDOW_SIZE - 1\n",
    "    true_actions.append(np.concatenate(\n",
    "        (\n",
    "            steps[final_window_step]['action']['world_vector'],\n",
    "            steps[final_window_step]['action']['rotation_delta'],\n",
    "            np.array(steps[final_window_step]['action']['open_gripper']).astype(np.float32)[None]\n",
    "        ), axis=-1\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
